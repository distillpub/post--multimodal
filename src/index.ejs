<!DOCTYPE html>

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=1300">
  <style id="distill-article-specific-styles">
    <%=require("../static/styles.css") %>
  </style>
  <script src="https://distill.pub/template.v2.js"></script>
</head>

<body>
  <d-front-matter>
    <script type="text/json">
      <%= JSON.stringify(require("./frontmatter.json"), null, 4) %>
    </script>
  </d-front-matter>

  <d-title>
    <h1>Multimodal Neurons in Artificial Neural Networks</h1>
  </d-title>

  <d-article>
  </d-article>

  <d-appendix>

    <h3>Acknowledgments</h3>
    <p>
      We are deeply grateful to Sandhini Agarwal, Daniela Amodei, Dario Amodei, Tom Brown, Jeff Clune, Steve Dowling, Gretchen Krueger, Brice Menard, Reiichiro Nakano, Aditya Ramesh, Pranav Shyam, Ilya Sutskever and Martin Wattenberg.
    </p>

    <h3>Author Contributions</h3>
      <div style="padding-top: 8px">
      <i>Gabriel Goh:</i> Research lead. Gabriel Goh first discovered multimodal neurons, sketched out the project direction and paper outline, and did much of the conceptual and engineering work that allowed the team to investigate the models in a scalable way. This included developing tools for understanding how concepts were built up and decomposed (that were applied to emotion neurons), developing zero-shot neuron search (that allowed easy discoverability of neurons), and working with Michael Petrov on porting CLIP to microscope. Subsequently developed faceted feature visualization, and text feature visualization. 
      </div style="padding-top: 8px">
      <div style="padding-top: 8px">
      <i>Alec Radford:</i> Developed CLIP. First observed that CLIP was learning to read. Advised Gabriel Goh on project direction on a weekly basis. Upon the discovery that CLIP was using text to classify images, proposed typographical adversarial attacks as a promising research direction. 
      </div style="padding-top: 8px">
      <div style="padding-top: 8px">
      <i>Chris Olah:</i> Worked with Gabe on the overall framing of the article, actively mentored each member of the team through their work providing both high and low level contributions to their sections, and contributed to the text of much of the article, setting the stylistic tone. He worked with Gabe on understanding the neuroscience literature and better understanding the relevant neuroscience literature. Additionally, he wrote the sections on region neurons and developed diversity feature visualization which Gabe used to create faceted feature visualization
      </div>
      <div style="padding-top: 8px">
      <i>Shan Carter:</i> Worked on initial investigation of CLIP with Gabriel Goh. Did multimodal activation atlases to understand the space of multimodal representations and geometry, and neuron atlases, which potentially helped the arrangement and display of neurons. Provided much useful advice on the visual presentation of ideas, and helped with many aspects of visual design. 
      </div style="padding-top: 8px">
      <div style="padding-top: 8px">
      <i>Michael Petrov:</i> Worked on the initial investigation of multimodal neurons by implementing and scaling dataset examples. Discovered, with Gabriel Goh, the original "Spider-Man" multimodal neuron in the dataset examples, and many more multimodal neurons. Assisted a lot in the engineering of Microscope both early on, and at the end, including helping Gabriel Goh with the difficult technical challenges of porting microscope to a different backend.
      </div style="padding-top: 8px">
      <div style="padding-top: 8px">
      <i>Chelsea Voss:</i> Performed investigation of the typographical attacks phenomena, both via linear probes and zero-shot, confirming that the attacks were indeed real and state of the art. Proposed and successfully found "in-the-wild" attacks in the zero-shot classifier. Subsequently wrote the section "typographical attacks". Upon completion of this part of the project, investigated responses of neurons to rendered text on dictionary words. Also assisted with the organization of neurons into neuron cards.
      </div style="padding-top: 8px">
      <div style="padding-top: 8px">
      <i>Nick Cammarata:</i> Drew the connection between multimodal neurons in neural networks and multimodal neurons in the brain, which became the overall framing of the article. Created the conditional probability plots (regional, Trump, mental health), labeling more than 1500 images, discovered that negative pre-ReLU activations are often interpretable, and discovered that neurons sometimes contain a distinct regime change between medium and strong activations. Wrote the identity section and the emotion sections, building off Gabriel’s discovery of emotion neurons and discovering that “complex” emotions can be broken down into simpler ones. Edited the overall text of the article and built infrastructure allowing the team to collaborate in Markdown with embeddable components.
      </div style="padding-top: 8px">
      <div style="padding-top: 8px">
      <i>Ludwig Schubert:</i> Helped with general infrastructure.
      </div>
      <h3>Discussion and Review</h3>
  <p>
    <a href="https://github.com/distillpub/post--multimodal/issues/1">Review 1 - Anonymous</a><br>
    <a href="https://github.com/distillpub/post--multimodal/issues/2">Review 2 - Anonymous</a><br>
    <a href="https://github.com/distillpub/post--multimodal/issues/3">Review 3 - Anonymous</a><br>
  </p>


    <d-footnote-list></d-footnote-list>
    <d-citation-list></d-citation-list>
  </d-appendix>

  <d-bibliography src="bibliography.bib"></d-bibliography>
</body>
