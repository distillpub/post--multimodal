<style>
  .reading-container {
    display: flex;
    flex-direction: row;
    width: 100%;
  }
  .reading-neuron-feature-viz {
    border-radius: 1em;
  }
  .reading-neuron-dataset-example {
    max-width: 48%;
    margin: 0px;
  }
  .reading-neuron {
    width: 30%;
    margin: 20px;
  }
</style>
<div class="reading-container">
  <div class="reading-neuron">
    <h4><a href="http://microscope-azure-edge.openai.com/models/contrastive_v2/image_block_4_2_Add_6_0/1535">RN101 Channel 1535</a></h4>
    <img class="reading-neuron-feature-viz" src="/typographic/RN101-channel-1535.png" alt="feature visualization with kissing faces and 'love you' text"/>
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1535-dataset-1.png" alt="kiss" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1535-dataset-2.png" alt="kiss me" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1535-dataset-3.png" alt="you kiss someone you love" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1535-dataset-4.png" alt="to be Kissed" />
    <p><small>"kiss", "love you"</small></p>
  </div>
  <div class="reading-neuron">
    <h4><a href="http://microscope-azure-edge.openai.com/models/contrastive_v2/image_block_4_2_Add_6_0/1882">RN101 Channel 1882</a></h4>
    <img class="reading-neuron-feature-viz" src="/typographic/RN101-channel-1882.png" alt="feature visualization with paper cards, the head of a turkey, and the words 'thank you'" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1882-dataset-1.png" alt="thank" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1882-dataset-2.png" alt="gracias" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1882-dataset-3.png" alt="thank you" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1882-dataset-4.png" alt="thank you" />
    <p><small>"thank you", "gracias"</small></p>
  </div>
  <div class="reading-neuron">
    <h4><a href="http://microscope-azure-edge.openai.com/models/contrastive_v2/image_block_4_2_Add_6_0/1738">RN101 Channel 1738</a></h4>
    <img class="reading-neuron-feature-viz" src="/typographic/RN101-channel-1738.png" alt="feature visualization with big ghostly text in the middle reminiscent of the text 2016 or 2015, small text around the edges with 2014 and 2015, and very faint fireworks" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1738-dataset-1.png" alt="2015" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1738-dataset-2.png" alt="year" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1738-dataset-3.png" alt="2016" />
    <img class="reading-neuron-dataset-example" src="/typographic/RN101-1738-dataset-4.png" alt="2013" />
    <p><small>"year", "2015", "2016", ...</small></p>
  </div>
</div>
<div class="figcaption">
 <p>
  <a class="figure-anchor" href="#literate-neurons">Figure N:</a> Three additional examples of neurons from Resnet-101 whose feature visualizations (top) and selected dataset examples (bottom) show sensitivity to specific words and text.
  </p>
</div>
